The Yorùbá Flickr Audio Caption Corpus (YFACC) dataset extends the [Flickr8k image-text dataset](https://forms.illinois.edu/sec/1713398) to Yorùbá with three modalities:

1. Yorùbá translations of 6k of the captions.
2. Corresponding spoken recordings of these translations, obtained from a single speaker.
3. Temporal alignments of 67 Yorùbá keywords for a subset of 500 of the captions.

The dataset is described in the following paper. Please cite the paper if you use the data:

- K. Olaleye, D. Oneață, and H. Kamper, "A Yorùbá speech-image dataset for cross-lingual keyword localisation through visual grounding," accepted to *SLT*, 2022. [[arXiv](missing_link)]


## Download

YFACC (6.8 GB): [yfacc_v6.tar.gz](missing_link)  
MD5 checksum: 774b9e00e36f5c848ea106c46a98176b


## License

Kayode Olaleye, Dan Oneață̆, Herman Kamper, 2022.  
This work is released under a Creative Commons Attribution-ShareAlike
license ([CC BY-SA 4.0](http://creativecommons.org/licenses/by-sa/4.0/)).
